{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6ad4291-3200-436a-aa76-ab14aa7bed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import random\n",
    "from tensorflow.keras import utils\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a424400-80b9-491a-9396-7cdaa488ffbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_genres = {'Blues':0, 'Classical':1, 'Country':2, 'Disco':3, 'Hip-Hop':4, 'Jazz':5, 'Metal':6, 'Pop':7, 'Reggae':8, 'Rock':9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ef0dd71-9d23-4fb5-9221-7fc0b31902d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectogram(audio_path):\n",
    "    y, sr = librosa.load(audio_path)\n",
    "    spect = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    spect = librosa.power_to_db(spect, ref=np.max)\n",
    "    return spect.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f3ceed1-a099-4187-b602-202144978330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(X_data, y_data):\n",
    "    X_data_split = []\n",
    "    for x in X_data:\n",
    "        X_data_split.extend(np.split(x, 10))\n",
    "\n",
    "    X_data_split = np.array(X_data_split)\n",
    "    y_data_split = np.repeat(y_data, 10, axis=0)\n",
    "    print(X_data_split.shape, y_data_split.shape)\n",
    "    \n",
    "    return X_data_split, y_data_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc2f9a91-587f-4cd8-8641-abea8b90bccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_array(g):\n",
    "    genres = []\n",
    "    X_spect = np.empty((0, 1280, 128))\n",
    "    count = 0\n",
    "    #Code skips records in case of errors\n",
    "    print(g)\n",
    "    for filename in os.listdir(os.path.join('data/genres_original/',f'{g}')):\n",
    "        try:\n",
    "            count += 1\n",
    "            audio_path = os.path.join(f'data/genres_original/{g}',f'{filename}')\n",
    "            spect = create_spectogram(audio_path)\n",
    "\n",
    "            # Normalize for small shape differences\n",
    "            spect = spect[:1280, :]\n",
    "            X_spect = np.append(X_spect, [spect], axis=0)\n",
    "            genres.append(dict_genres[g])\n",
    "            if count % 100 == 0:\n",
    "                print(\"Currently processing: \", count)\n",
    "        except:\n",
    "            print(\"Couldn't process: \", count)\n",
    "            continue\n",
    "    y_arr = np.array(genres)\n",
    "    \n",
    "    X_spect, y_arr = data_split(X_spect, y_arr)\n",
    "    \n",
    "    return X_spect, y_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "644a2428-bc44-4e95-a66b-bd09f21a0f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blues\n",
      "Currently processing:  100\n",
      "(1000, 128, 128) (1000,)\n",
      "Classical\n",
      "Currently processing:  100\n",
      "(1000, 128, 128) (1000,)\n",
      "Country\n",
      "Currently processing:  100\n",
      "(1000, 128, 128) (1000,)\n",
      "Disco\n",
      "Currently processing:  100\n",
      "(1000, 128, 128) (1000,)\n",
      "Hip-Hop\n",
      "Currently processing:  100\n",
      "(1000, 128, 128) (1000,)\n",
      "Jazz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriele\\anaconda3\\envs\\music-genre-recognition\\lib\\site-packages\\librosa\\core\\audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't process:  55\n",
      "Currently processing:  100\n",
      "(990, 128, 128) (990,)\n",
      "Metal\n",
      "Currently processing:  100\n",
      "(1000, 128, 128) (1000,)\n",
      "Pop\n",
      "Currently processing:  100\n",
      "(1000, 128, 128) (1000,)\n",
      "Reggae\n",
      "Currently processing:  100\n",
      "(1000, 128, 128) (1000,)\n",
      "Rock\n",
      "Currently processing:  100\n",
      "(1000, 128, 128) (1000,)\n"
     ]
    }
   ],
   "source": [
    "X_data_genre = [[],[],[],[],[],[],[],[],[],[]]\n",
    "y_data_genre = [[],[],[],[],[],[],[],[],[],[]]\n",
    "\n",
    "for g, i in list(dict_genres.items()):\n",
    "    X_data_genre[i], y_data_genre[i] = create_array(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7b57e0e-63a1-4926-88d1-9d9f2af00bd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def shuffle_data(X_data, y_data):\n",
    "    training_data = []\n",
    "    for i in range(X_data.shape[0]):\n",
    "        training_data.append((X_data[i], y_data[i]))\n",
    "    \n",
    "    random.shuffle(training_data)\n",
    "    \n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebf10640-a666-4a6d-b366-b97a9c2247bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for frames, labels in data:\n",
    "        X.append(frames)\n",
    "        y.append(labels)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e94d066c-0942-4391-8a49-e9665c08e8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_data(training_data):\n",
    "    X_train, y_train = prepare_data(training_data)\n",
    "\n",
    "    # Calculate validation and test set sizes\n",
    "    val_set_size = 100\n",
    "    test_set_size = 100\n",
    "\n",
    "    # Break x apart into train, validation, and test sets\n",
    "    X_valid = X_train[:val_set_size]\n",
    "    X_test = X_train[val_set_size:(val_set_size + test_set_size)]\n",
    "    X_train = X_train[(val_set_size + test_set_size):]\n",
    "\n",
    "    # Break y apart into train, validation, and test sets\n",
    "    y_valid = y_train[:val_set_size]\n",
    "    y_test = y_train[val_set_size:(val_set_size + test_set_size)]\n",
    "    y_train = y_train[(val_set_size + test_set_size):]\n",
    "\n",
    "    print(\"Train set size: \" + str(len(X_train)))\n",
    "    print(\"Validation set size: \" + str(len(X_valid)))\n",
    "    print(\"Test set size: \" + str(len(X_test)))\n",
    "    \n",
    "    return np.array(X_train), np.array(y_train), np.array(X_valid), np.array(y_valid), np.array(X_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cec801fd-dcf2-426d-88be-7d658c50408a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blues\n",
      "Train set size: 800\n",
      "Validation set size: 100\n",
      "Test set size: 100\n",
      "Classical\n",
      "Train set size: 800\n",
      "Validation set size: 100\n",
      "Test set size: 100\n",
      "Country\n",
      "Train set size: 800\n",
      "Validation set size: 100\n",
      "Test set size: 100\n",
      "Disco\n",
      "Train set size: 800\n",
      "Validation set size: 100\n",
      "Test set size: 100\n",
      "Hip-Hop\n",
      "Train set size: 800\n",
      "Validation set size: 100\n",
      "Test set size: 100\n",
      "Jazz\n",
      "Train set size: 790\n",
      "Validation set size: 100\n",
      "Test set size: 100\n",
      "Metal\n",
      "Train set size: 800\n",
      "Validation set size: 100\n",
      "Test set size: 100\n",
      "Pop\n",
      "Train set size: 800\n",
      "Validation set size: 100\n",
      "Test set size: 100\n",
      "Reggae\n",
      "Train set size: 800\n",
      "Validation set size: 100\n",
      "Test set size: 100\n",
      "Rock\n",
      "Train set size: 800\n",
      "Validation set size: 100\n",
      "Test set size: 100\n"
     ]
    }
   ],
   "source": [
    "X_train_genre = [[],[],[],[],[],[],[],[],[],[]]\n",
    "y_train_genre = [[],[],[],[],[],[],[],[],[],[]]\n",
    "X_valid_genre = [[],[],[],[],[],[],[],[],[],[]]\n",
    "y_valid_genre = [[],[],[],[],[],[],[],[],[],[]]\n",
    "X_test_genre = [[],[],[],[],[],[],[],[],[],[]]\n",
    "y_test_genre = [[],[],[],[],[],[],[],[],[],[]]\n",
    "\n",
    "for g, i in list(dict_genres.items()):\n",
    "    print(g)\n",
    "    training_data = shuffle_data(X_data_genre[i], y_data_genre[i])\n",
    "    X_train_genre[i], y_train_genre[i], X_valid_genre[i], y_valid_genre[i], X_test_genre[i], y_test_genre[i] = partition_data(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5481233-3413-42b9-b9fe-cce2d2b46c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train_genre[0], \n",
    "                          X_train_genre[1], \n",
    "                          X_train_genre[2], \n",
    "                          X_train_genre[3], \n",
    "                          X_train_genre[4], \n",
    "                          X_train_genre[5], \n",
    "                          X_train_genre[6], \n",
    "                          X_train_genre[7], \n",
    "                          X_train_genre[8], \n",
    "                          X_train_genre[9]), axis = 0)\n",
    "\n",
    "y_train = np.concatenate((y_train_genre[0], \n",
    "                         y_train_genre[1], \n",
    "                         y_train_genre[2], \n",
    "                         y_train_genre[3], \n",
    "                         y_train_genre[4], \n",
    "                         y_train_genre[5], \n",
    "                         y_train_genre[6], \n",
    "                         y_train_genre[7], \n",
    "                         y_train_genre[8], \n",
    "                         y_train_genre[9]), axis = 0)\n",
    "\n",
    "X_valid = np.concatenate((X_valid_genre[0], \n",
    "                          X_valid_genre[1], \n",
    "                          X_valid_genre[2], \n",
    "                          X_valid_genre[3], \n",
    "                          X_valid_genre[4], \n",
    "                          X_valid_genre[5], \n",
    "                          X_valid_genre[6], \n",
    "                          X_valid_genre[7], \n",
    "                          X_valid_genre[8], \n",
    "                          X_valid_genre[9]), axis = 0)\n",
    "\n",
    "y_valid = np.concatenate((y_valid_genre[0], \n",
    "                          y_valid_genre[1], \n",
    "                          y_valid_genre[2], \n",
    "                          y_valid_genre[3], \n",
    "                          y_valid_genre[4], \n",
    "                          y_valid_genre[5], \n",
    "                          y_valid_genre[6], \n",
    "                          y_valid_genre[7], \n",
    "                          y_valid_genre[8], \n",
    "                          y_valid_genre[9]), axis = 0)\n",
    "\n",
    "X_test = np.concatenate((X_test_genre[0], \n",
    "                         X_test_genre[1], \n",
    "                         X_test_genre[2], \n",
    "                         X_test_genre[3], \n",
    "                         X_test_genre[4], \n",
    "                         X_test_genre[5], \n",
    "                         X_test_genre[6], \n",
    "                         X_test_genre[7], \n",
    "                         X_test_genre[8], \n",
    "                         X_test_genre[9]), axis = 0)\n",
    "\n",
    "y_test = np.concatenate((y_test_genre[0], \n",
    "                         y_test_genre[1], \n",
    "                         y_test_genre[2], \n",
    "                         y_test_genre[3], \n",
    "                         y_test_genre[4], \n",
    "                         y_test_genre[5], \n",
    "                         y_test_genre[6], \n",
    "                         y_test_genre[7], \n",
    "                         y_test_genre[8], \n",
    "                         y_test_genre[9]), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400060e4-289c-451c-b3c4-543661e70b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd3265b1-6574-4c99-82c6-9f8410c8c4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-08 1.0000008783668917 0.0035998650525228457\n",
      "-18.420680743952367 8.783665059016772e-07 -9.850973296132196\n"
     ]
    }
   ],
   "source": [
    "### Convert the scale of training data\n",
    "X_train_raw = librosa.core.db_to_power(X_train, ref=1.0)\n",
    "X_train_log = np.log(X_train_raw)\n",
    "print(np.amin(X_train_raw), np.amax(X_train_raw), np.mean(X_train_raw))\n",
    "print(np.amin(X_train_log), np.amax(X_train_log), np.mean(X_train_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90e44f3b-db32-42ce-b3bd-708c9088e1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-08 1.0000008783668917 0.0035179373293953045\n",
      "-18.420680743952367 8.783665059016772e-07 -9.927011884488092\n"
     ]
    }
   ],
   "source": [
    "X_valid_raw = librosa.core.db_to_power(X_valid, ref=1.0)\n",
    "X_valid_log = np.log(X_valid_raw)\n",
    "print(np.amin(X_valid_raw), np.amax(X_valid_raw), np.mean(X_valid_raw))\n",
    "print(np.amin(X_valid_log), np.amax(X_valid_log), np.mean(X_valid_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b74e77bf-62a0-4ce8-8649-5f7e5f34e5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-08 1.0000008783668917 0.003660368779788147\n",
      "-18.420680743952367 8.783665059016772e-07 -9.807614811357396\n"
     ]
    }
   ],
   "source": [
    "X_test_raw = librosa.core.db_to_power(X_test, ref=1.0)\n",
    "X_test_log = np.log(X_test_raw)\n",
    "print(np.amin(X_test_raw), np.amax(X_test_raw), np.mean(X_test_raw))\n",
    "print(np.amin(X_test_log), np.amax(X_test_log), np.mean(X_test_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df02b9de-bc17-4f6e-936b-32aa10d69ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_train_log, y_train\n",
    "X_valid, y_valid = X_valid_log, y_valid\n",
    "X_test, y_test = X_test_log, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe9f720-424f-4c9c-a494-964a2cc8a5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be76fddf-fb27-4665-8142-18fd0ca7214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_targets_sets_train = shuffle_data(X_train, y_train)\n",
    "all_targets_sets_valid = shuffle_data(X_valid, y_valid)\n",
    "all_targets_sets_test = shuffle_data(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09950372-fa9c-4303-8cfb-045614afe74a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c9a030c-f8ed-46c6-a257-954af93b1472",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = prepare_data(all_targets_sets_train)\n",
    "X_valid, y_valid = prepare_data(all_targets_sets_valid)\n",
    "X_test, y_test = prepare_data(all_targets_sets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ad82ca-279f-4ad2-b1bb-17365a1bb68f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2ef9aeb-007e-4f07-84cf-0aa260c34920",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_valid, y_valid = np.array(X_valid), np.array(y_valid)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db12d1c1-e83c-4985-9875-81437bb2189b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe19d6e5-d1f5-4e2b-a7f0-fbb03d8f5af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = utils.to_categorical(y_train, num_classes=10).astype(int)\n",
    "y_valid = utils.to_categorical(y_valid, num_classes=10).astype(int)\n",
    "y_test = utils.to_categorical(y_test, num_classes=10).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fe5be4-fb1b-4ec7-80b0-fa3b25b20d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7be67818-b089-4162-985e-68210146867e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shapes:  (7990, 128, 128) (7990, 10)\n",
      "Validation set shapes:  (1000, 128, 128) (1000, 10)\n",
      "Test set shapes:  (1000, 128, 128) (1000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set shapes: \", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shapes: \", X_valid.shape, y_valid.shape)\n",
    "print(\"Test set shapes: \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5561989a-49cf-437a-b300-79c68f7484c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('data/all_targets_sets_train_new', X_train, y_train)\n",
    "np.savez('data/all_targets_sets_valid_new', X_valid, y_valid)\n",
    "np.savez('data/all_targets_sets_test_new', X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0508909-e5b9-469a-bb9b-ab292fa5fbf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe31c9a3-ae53-4c25-962d-b603a693b778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
